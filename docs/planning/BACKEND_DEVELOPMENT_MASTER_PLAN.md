# GX Protocol Backend Development - Master Plan
## Production-Ready Microservices Architecture

**Project Start Date:** November 13, 2025
**Target Completion:** December 11, 2025 (4 weeks)
**Development Approach:** Phased, Agile, Test-Driven
**Documentation Style:** Lecture-based, comprehensive, industry-standard

---

## Executive Summary

This document outlines the complete development plan for the GX Protocol Backend system - a production-ready, enterprise-grade microservices architecture implementing CQRS/Event-Driven patterns for blockchain integration.

**Key Deliverables:**
1. **Wallet API** - Complete digital wallet functionality with multi-signature support
2. **Licensing System** - Partner licensing, API key management, rate limiting
3. **Identity Service** - User registration, KYC, authentication
4. **CQRS Workers** - Reliable blockchain integration with outbox/projector pattern
5. **Infrastructure** - PostgreSQL, Redis, monitoring, security hardening
6. **CI/CD Pipeline** - Automated testing, deployment, rollback capabilities

**Architecture Principles:**
- Microservices with domain-driven design
- CQRS for blockchain writes, read models for queries
- Event sourcing from Fabric blockchain
- Idempotent APIs with distributed transaction support
- Multi-environment deployment (devnet, testnet, mainnet)
- Production-grade observability and security

---

## Phase Structure Overview

```
Phase 0: Planning & Setup            (Week 0, Days 1-2)    ‚úì Current Phase
Phase 1: Infrastructure Foundation   (Week 1, Days 1-3)
Phase 2: Fabric Integration          (Week 1, Days 4-7)
Phase 3: CQRS Workers                (Week 2, Days 8-10)
Phase 4: Core APIs                   (Week 2-3, Days 11-17)
Phase 5: Security & Monitoring       (Week 3, Days 18-21)
Phase 6: Testing & Deployment        (Week 4, Days 22-28)
```

---

## Phase 0: Planning & Documentation Setup
### Days 1-2 (Nov 13-14, 2025)

**Status:** üîµ IN PROGRESS

### Objectives
- Establish comprehensive project plan
- Create documentation structure
- Set up task tracking system
- Define success criteria and KPIs
- Validate architecture decisions

### Tasks

#### 0.1 Documentation Structure Setup ‚úì
```bash
docs/
‚îú‚îÄ‚îÄ planning/
‚îÇ   ‚îú‚îÄ‚îÄ BACKEND_DEVELOPMENT_MASTER_PLAN.md     (This file)
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE_DECISIONS.md
‚îÇ   ‚îî‚îÄ‚îÄ SUCCESS_CRITERIA.md
‚îú‚îÄ‚îÄ phases/
‚îÇ   ‚îú‚îÄ‚îÄ phase-0-planning/
‚îÇ   ‚îú‚îÄ‚îÄ phase-1-infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ phase-2-fabric-integration/
‚îÇ   ‚îú‚îÄ‚îÄ phase-3-cqrs-workers/
‚îÇ   ‚îú‚îÄ‚îÄ phase-4-core-apis/
‚îÇ   ‚îú‚îÄ‚îÄ phase-5-security/
‚îÇ   ‚îî‚îÄ‚îÄ phase-6-deployment/
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ daily/
‚îÇ   ‚îú‚îÄ‚îÄ weekly/
‚îÇ   ‚îî‚îÄ‚îÄ phase-completions/
‚îî‚îÄ‚îÄ lectures/
    ‚îú‚îÄ‚îÄ 001-cqrs-pattern-implementation.md
    ‚îú‚îÄ‚îÄ 002-fabric-sdk-integration.md
    ‚îú‚îÄ‚îÄ 003-event-driven-architecture.md
    ‚îî‚îÄ‚îÄ ...
```

#### 0.2 Architecture Validation
- [ ] Review existing Fabric network configuration
- [ ] Validate CQRS pattern alignment with chaincode
- [ ] Confirm database schema matches read model requirements
- [ ] Verify network topology (devnet, testnet, mainnet namespaces)
- [ ] Document API contract specifications

#### 0.3 Environment Preparation
- [ ] Verify Kubernetes cluster access (kubectl configured)
- [ ] Confirm Docker registry availability
- [ ] Set up development environment variables
- [ ] Clone and organize repositories
- [ ] Install required tools (Node.js 20, Go 1.21, kubectl, Docker)

#### 0.4 Team Alignment
- [ ] Review project scope and timeline
- [ ] Define communication protocols
- [ ] Establish code review standards
- [ ] Set up git workflow (feature branches, PR process)
- [ ] Create incident response plan

### Deliverables
- ‚úì Master plan document
- [ ] Architecture decision records (ADRs)
- [ ] Documentation templates
- [ ] Success criteria definition
- [ ] Initial task breakdown

### Success Criteria
- All documentation directories created
- Master plan approved and published
- Development environment validated
- Team aligned on approach

---

## Phase 1: Infrastructure Foundation
### Week 1, Days 1-3 (Nov 15-17, 2025)

**Status:** ‚è≥ PENDING

### Objectives
- Deploy PostgreSQL cluster for backend data
- Deploy Redis cluster for caching and idempotency
- Set up Kubernetes namespaces and RBAC
- Configure secrets management
- Establish database schemas with Prisma

### Tasks

#### 1.1 Kubernetes Namespace Setup (Day 1 Morning)

**Create namespaces for multi-environment deployment:**
```bash
kubectl create namespace backend-mainnet
kubectl create namespace backend-testnet
kubectl create namespace backend-devnet
```

**Namespace Labels:**
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: backend-mainnet
  labels:
    environment: production
    component: backend
    monitoring: enabled
```

**Tasks:**
- [ ] Create backend-mainnet namespace
- [ ] Create backend-testnet namespace
- [ ] Create backend-devnet namespace
- [ ] Apply ResourceQuotas (CPU: 8 cores, Memory: 16Gi per namespace)
- [ ] Configure LimitRanges for pods
- [ ] Set up NetworkPolicies (deny-all by default)
- [ ] Create ServiceAccounts for backend services

#### 1.2 PostgreSQL Deployment (Day 1 Afternoon - Day 2 Morning)

**Architecture:**
- Primary database with 2 read replicas
- Persistent storage with SSD-backed PVCs
- Automated backups every 6 hours
- Connection pooling with PgBouncer

**Deployment:**
```yaml
# k8s/infrastructure/postgres-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: backend-mainnet
spec:
  serviceName: postgres
  replicas: 3  # 1 primary + 2 replicas
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: gx_protocol
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 100Gi
```

**Tasks:**
- [ ] Create postgres-credentials Secret
- [ ] Deploy PostgreSQL StatefulSet (3 replicas)
- [ ] Create postgres-primary Service (write operations)
- [ ] Create postgres-replica Service (read operations)
- [ ] Configure PgBouncer connection pooler
- [ ] Set up automated backups (CronJob every 6 hours)
- [ ] Test connection from backend namespace
- [ ] Verify replication lag (<100ms)
- [ ] Run database initialization scripts

#### 1.3 Database Schema Migration (Day 2 Afternoon)

**Prisma Schema:**
```prisma
// db/prisma/schema.prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

// Outbox Pattern (CQRS Write Path)
model OutboxCommand {
  id              String    @id @default(uuid())
  aggregateId     String    // User ID, Org ID, etc.
  commandType     String    // "Identity:CreateUser", "Tokenomics:Transfer"
  payload         Json
  status          String    @default("PENDING") // PENDING, PROCESSING, COMPLETED, FAILED
  attempts        Int       @default(0)
  maxAttempts     Int       @default(5)
  error           String?
  idempotencyKey  String?   @unique
  createdAt       DateTime  @default(now())
  processedAt     DateTime?

  @@index([status, createdAt])
  @@index([aggregateId])
  @@index([idempotencyKey])
}

// Projector State (Event Processing Checkpoint)
model ProjectorState {
  id              String   @id @default(uuid())
  blockNumber     BigInt   @default(0)
  transactionId   String?
  lastEventId     String?
  lastEventTime   DateTime?
  updatedAt       DateTime @updatedAt
}

// HTTP Idempotency (24-hour TTL)
model HttpIdempotency {
  idempotencyKey  String    @id
  endpoint        String
  method          String
  statusCode      Int
  responseBody    Json
  createdAt       DateTime  @default(now())
  expiresAt       DateTime

  @@index([expiresAt])
}

// User Profile (Read Model - Projected from Fabric)
model UserProfile {
  userId          String    @id
  biometricHash   String?
  nationality     String
  trustScore      Int       @default(0)
  status          String    @default("ACTIVE") // ACTIVE, SUSPENDED, BANNED
  genesisMinted   Boolean   @default(false)
  createdAt       DateTime
  updatedAt       DateTime  @updatedAt

  // Relations
  wallets         Wallet[]
  sentTransfers   Transaction[] @relation("SentTransfers")
  receivedTransfers Transaction[] @relation("ReceivedTransfers")

  @@index([nationality])
  @@index([status])
}

// Wallet (Read Model)
model Wallet {
  walletId        String    @id @default(uuid())
  userId          String
  balance         BigInt    @default(0)
  lockedBalance   BigInt    @default(0)
  lastUpdated     DateTime  @updatedAt

  user            UserProfile @relation(fields: [userId], references: [userId])

  @@index([userId])
}

// Transaction History (Read Model)
model Transaction {
  txId            String    @id
  blockNumber     BigInt
  transactionId   String
  fromUserId      String
  toUserId        String
  amount          BigInt
  fee             BigInt    @default(0)
  type            String    // TRANSFER, GENESIS, MINT, BURN
  status          String    // PENDING, COMPLETED, FAILED
  metadata        Json?
  timestamp       DateTime

  sender          UserProfile @relation("SentTransfers", fields: [fromUserId], references: [userId])
  recipient       UserProfile @relation("ReceivedTransfers", fields: [toUserId], references: [userId])

  @@index([fromUserId])
  @@index([toUserId])
  @@index([timestamp])
  @@index([type])
}

// Licensing System
model License {
  licenseId       String    @id @default(uuid())
  partnerId       String
  tier            String    // FREE, BASIC, PREMIUM, ENTERPRISE
  apiKey          String    @unique
  rateLimit       Int       // Requests per minute
  status          String    @default("ACTIVE") // ACTIVE, SUSPENDED, EXPIRED
  expiresAt       DateTime?
  createdAt       DateTime  @default(now())
  updatedAt       DateTime  @updatedAt

  partner         Partner @relation(fields: [partnerId], references: [partnerId])
  apiCalls        ApiCall[]

  @@index([apiKey])
  @@index([partnerId])
  @@index([status])
}

// Partner Organizations
model Partner {
  partnerId       String    @id @default(uuid())
  name            String
  email           String    @unique
  contactPerson   String
  phone           String?
  address         String?
  status          String    @default("PENDING") // PENDING, APPROVED, SUSPENDED
  createdAt       DateTime  @default(now())
  updatedAt       DateTime  @updatedAt

  licenses        License[]

  @@index([status])
}

// API Call Tracking
model ApiCall {
  callId          String    @id @default(uuid())
  licenseId       String
  endpoint        String
  method          String
  statusCode      Int
  responseTime    Int       // milliseconds
  ipAddress       String
  userAgent       String?
  timestamp       DateTime  @default(now())

  license         License @relation(fields: [licenseId], references: [licenseId])

  @@index([licenseId, timestamp])
  @@index([timestamp])
}
```

**Migration Tasks:**
- [ ] Initialize Prisma project
- [ ] Create initial migration
- [ ] Run migration on mainnet database
- [ ] Run migration on testnet database
- [ ] Run migration on devnet database
- [ ] Generate Prisma Client
- [ ] Create seed data for testing
- [ ] Verify schema matches Fabric events

#### 1.4 Redis Deployment (Day 3 Morning)

**Architecture:**
- Redis Sentinel for high availability (1 master + 2 replicas)
- AOF + RDB persistence
- Memory limit: 4GB per instance
- Use cases: Idempotency keys, rate limiting, session storage

**Deployment:**
```yaml
# k8s/infrastructure/redis-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: backend-mainnet
spec:
  serviceName: redis
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
          name: redis
        command:
        - redis-server
        - --appendonly yes
        - --save 900 1
        - --save 300 10
        - --save 60 10000
        - --maxmemory 4gb
        - --maxmemory-policy allkeys-lru
        volumeMounts:
        - name: redis-storage
          mountPath: /data
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "1000m"
  volumeClaimTemplates:
  - metadata:
      name: redis-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

**Tasks:**
- [ ] Deploy Redis StatefulSet
- [ ] Configure Redis Sentinel for failover
- [ ] Create redis-master Service
- [ ] Create redis-replica Service
- [ ] Test connection from backend namespace
- [ ] Verify persistence (AOF + RDB)
- [ ] Configure memory eviction policies
- [ ] Test failover scenario

#### 1.5 Secrets Management (Day 3 Afternoon)

**Kubernetes Secrets:**
```bash
# Create database credentials
kubectl create secret generic postgres-credentials \
  --from-literal=username=gx_backend \
  --from-literal=password=$(openssl rand -base64 32) \
  -n backend-mainnet

# Create Fabric credentials
kubectl create secret generic fabric-credentials \
  --from-file=connection-profile=./config/connection-profiles/mainnet-connection.yaml \
  --from-file=tls-cert=./fabric-certs/tls/server.crt \
  --from-file=tls-key=./fabric-certs/tls/server.key \
  -n backend-mainnet

# Create JWT signing keys
kubectl create secret generic jwt-keys \
  --from-literal=private-key=$(openssl genrsa 4096 | base64) \
  --from-literal=public-key=$(openssl rsa -pubout | base64) \
  -n backend-mainnet
```

**Tasks:**
- [ ] Generate strong passwords for all services
- [ ] Create postgres-credentials Secret
- [ ] Create redis-password Secret
- [ ] Create fabric-credentials Secret
- [ ] Create jwt-keys Secret
- [ ] Create api-keys Secret (for external partners)
- [ ] Document secret rotation procedures
- [ ] Set up automated secret rotation (90 days)

### Phase 1 Deliverables
- ‚úì Kubernetes namespaces operational (3 environments)
- ‚úì PostgreSQL cluster deployed (primary + 2 replicas)
- ‚úì Database schemas migrated (38 tables)
- ‚úì Redis cluster operational with Sentinel
- ‚úì All secrets created and documented

### Phase 1 Success Criteria
- [ ] PostgreSQL accepting connections (<10ms latency)
- [ ] Database replication lag <100ms
- [ ] Redis cluster responding (<1ms latency)
- [ ] All secrets securely stored
- [ ] Backup system tested (successful restore)

---

## Phase 2: Fabric SDK Integration
### Week 1, Days 4-7 (Nov 18-21, 2025)

**Status:** ‚è≥ PENDING

### Objectives
- Integrate Hyperledger Fabric SDK
- Create Fabric Gateway connection manager
- Implement identity and wallet management
- Test chaincode invocation from backend
- Set up event listener infrastructure

### Tasks

#### 2.1 Fabric SDK Package Setup (Day 4)

**Package: @gx/core-fabric**
```typescript
// packages/core-fabric/src/index.ts
export { FabricGateway } from './gateway';
export { FabricEventListener } from './event-listener';
export { WalletManager } from './wallet-manager';
export { ConnectionProfile } from './connection-profile';
export * from './types';
```

**Tasks:**
- [ ] Create @gx/core-fabric package structure
- [ ] Install fabric-network@2.5 SDK
- [ ] Install fabric-ca-client@2.5
- [ ] Create TypeScript interfaces for all types
- [ ] Implement connection profile loader
- [ ] Create environment-specific configurations

#### 2.2 Gateway Connection Manager (Day 4-5)

**Implementation:**
```typescript
// packages/core-fabric/src/gateway.ts
import { Gateway, Wallets, Network, Contract, Wallet } from 'fabric-network';
import { logger } from '@gx/core-logger';

export class FabricGateway {
  private gateway: Gateway | null = null;
  private network: Network | null = null;
  private contract: Contract | null = null;
  private wallet: Wallet | null = null;

  constructor(
    private readonly networkId: string, // 'mainnet', 'testnet', 'devnet'
    private readonly config: FabricConfig
  ) {}

  async connect(): Promise<void> {
    try {
      // Load connection profile
      const connectionProfile = await this.loadConnectionProfile();

      // Load wallet with identity
      this.wallet = await Wallets.newFileSystemWallet(this.config.walletPath);
      const identity = await this.wallet.get(this.config.identityLabel);

      if (!identity) {
        throw new Error(`Identity ${this.config.identityLabel} not found`);
      }

      // Create and connect gateway
      this.gateway = new Gateway();
      await this.gateway.connect(connectionProfile, {
        wallet: this.wallet,
        identity: this.config.identityLabel,
        discovery: {
          enabled: true,
          asLocalhost: this.networkId === 'devnet'
        },
        eventHandlerOptions: {
          strategy: 'MSPID_SCOPE_ALLFORTX'
        }
      });

      // Get network and contract
      this.network = await this.gateway.getNetwork(this.config.channelName);
      this.contract = this.network.getContract(this.config.chaincodeName);

      logger.info('Fabric Gateway connected', {
        networkId: this.networkId,
        channel: this.config.channelName,
        chaincode: this.config.chaincodeName
      });
    } catch (error) {
      logger.error('Failed to connect Fabric Gateway', { error });
      throw error;
    }
  }

  async submitTransaction(
    functionName: string,
    ...args: string[]
  ): Promise<Buffer> {
    if (!this.contract) {
      throw new Error('Gateway not connected');
    }

    try {
      const startTime = Date.now();
      const result = await this.contract.submitTransaction(functionName, ...args);
      const duration = Date.now() - startTime;

      logger.info('Transaction submitted', {
        function: functionName,
        duration,
        argsCount: args.length
      });

      return result;
    } catch (error) {
      logger.error('Transaction submission failed', {
        function: functionName,
        error
      });
      throw error;
    }
  }

  async evaluateTransaction(
    functionName: string,
    ...args: string[]
  ): Promise<Buffer> {
    if (!this.contract) {
      throw new Error('Gateway not connected');
    }

    return await this.contract.evaluateTransaction(functionName, ...args);
  }

  async disconnect(): Promise<void> {
    if (this.gateway) {
      this.gateway.disconnect();
      this.gateway = null;
      this.network = null;
      this.contract = null;
      logger.info('Fabric Gateway disconnected');
    }
  }

  private async loadConnectionProfile(): Promise<any> {
    const profilePath = `${this.config.connectionProfilesPath}/${this.networkId}-connection.yaml`;
    // Load and parse YAML connection profile
    return loadYamlFile(profilePath);
  }
}
```

**Tasks:**
- [ ] Implement FabricGateway class
- [ ] Add connection pooling (max 10 connections)
- [ ] Implement retry logic with exponential backoff
- [ ] Add circuit breaker pattern
- [ ] Create health check mechanism
- [ ] Test connection to mainnet Fabric network
- [ ] Test connection to testnet Fabric network
- [ ] Verify chaincode invocation (Admin:GetSystemStatus)

#### 2.3 Identity & Wallet Management (Day 5-6)

**Implementation:**
```typescript
// packages/core-fabric/src/wallet-manager.ts
import { Wallets, X509Identity, Wallet } from 'fabric-network';
import FabricCAServices from 'fabric-ca-client';

export class WalletManager {
  async enrollAdmin(
    caUrl: string,
    enrollmentId: string,
    enrollmentSecret: string,
    mspId: string
  ): Promise<void> {
    const ca = new FabricCAServices(caUrl);

    // Enroll admin
    const enrollment = await ca.enroll({
      enrollmentID: enrollmentId,
      enrollmentSecret: enrollmentSecret
    });

    const identity: X509Identity = {
      credentials: {
        certificate: enrollment.certificate,
        privateKey: enrollment.key.toBytes()
      },
      mspId: mspId,
      type: 'X.509'
    };

    const wallet = await Wallets.newFileSystemWallet('./wallets');
    await wallet.put(enrollmentId, identity);
  }

  async enrollPartnerApi(
    caUrl: string,
    adminIdentity: string,
    mspId: string
  ): Promise<void> {
    // Register and enroll partner API identity with gx_partner_api role
    const ca = new FabricCAServices(caUrl);
    const adminWallet = await Wallets.newFileSystemWallet('./wallets');
    const adminUser = await adminWallet.get(adminIdentity);

    // Register user with gx_partner_api attribute
    const secret = await ca.register({
      affiliation: 'org1.department1',
      enrollmentID: 'partner-api',
      role: 'client',
      attrs: [
        { name: 'gxc_role', value: 'gx_partner_api', ecert: true }
      ]
    }, adminUser);

    // Enroll partner API identity
    const enrollment = await ca.enroll({
      enrollmentID: 'partner-api',
      enrollmentSecret: secret
    });

    const identity: X509Identity = {
      credentials: {
        certificate: enrollment.certificate,
        privateKey: enrollment.key.toBytes()
      },
      mspId: mspId,
      type: 'X.509'
    };

    await adminWallet.put('partner-api', identity);
  }
}
```

**Tasks:**
- [ ] Extract TLS certificates from Kubernetes (fabric namespace)
- [ ] Create wallet directory structure (mainnet, testnet, devnet)
- [ ] Enroll admin identity from Fabric CA
- [ ] Enroll partner-api identity with gx_partner_api role
- [ ] Store identities in Kubernetes Secrets
- [ ] Mount identities in backend pods
- [ ] Test identity authentication
- [ ] Verify ABAC permissions (gx_partner_api can invoke chaincode)

#### 2.4 Event Listener Infrastructure (Day 6-7)

**Implementation:**
```typescript
// packages/core-fabric/src/event-listener.ts
import { Network, Contract, ContractListener, BlockListener } from 'fabric-network';
import { EventValidator } from '@gx/core-events';
import { logger } from '@gx/core-logger';

export class FabricEventListener {
  private blockListener: BlockListener | null = null;
  private contractListener: ContractListener | null = null;

  constructor(
    private readonly network: Network,
    private readonly contract: Contract
  ) {}

  async startBlockListener(
    callback: (blockNumber: number, transactions: any[]) => Promise<void>
  ): Promise<void> {
    this.blockListener = await this.network.addBlockListener(async (event) => {
      logger.info('Block received', {
        blockNumber: event.blockNumber.toString(),
        txCount: event.blockData.data.data.length
      });

      const blockNumber = parseInt(event.blockNumber.toString());
      const transactions = this.parseBlock(event);

      await callback(blockNumber, transactions);
    });

    logger.info('Block listener started');
  }

  async startContractListener(
    callback: (eventName: string, payload: any) => Promise<void>
  ): Promise<void> {
    this.contractListener = await this.contract.addContractListener(async (event) => {
      const eventName = event.eventName;
      const payloadString = event.payload.toString('utf8');
      const payload = JSON.parse(payloadString);

      logger.info('Chaincode event received', {
        event: eventName,
        txId: event.transactionId
      });

      // Validate event against schema
      const isValid = EventValidator.validate(eventName, payload);
      if (!isValid) {
        logger.error('Invalid event payload', { event: eventName, payload });
        return;
      }

      await callback(eventName, payload);
    });

    logger.info('Contract listener started');
  }

  async stop(): Promise<void> {
    if (this.blockListener) {
      this.blockListener.unregister();
      this.blockListener = null;
    }
    if (this.contractListener) {
      this.contractListener.unregister();
      this.contractListener = null;
    }
    logger.info('Event listeners stopped');
  }

  private parseBlock(event: any): any[] {
    // Parse block transactions and extract events
    const transactions = [];
    // ... implementation
    return transactions;
  }
}
```

**Tasks:**
- [ ] Implement block listener
- [ ] Implement chaincode event listener
- [ ] Add event validation (JSON Schema)
- [ ] Implement checkpointing (last processed block)
- [ ] Add replay capability for missed events
- [ ] Test event delivery from testnet
- [ ] Monitor event processing latency
- [ ] Create event handler registry

### Phase 2 Deliverables
- ‚úì Fabric SDK integrated (@gx/core-fabric package)
- ‚úì Gateway connection manager operational
- ‚úì Identities enrolled (admin, partner-api)
- ‚úì Chaincode invocation tested
- ‚úì Event listeners functional

### Phase 2 Success Criteria
- [ ] Can connect to Fabric network (<500ms)
- [ ] Can invoke chaincode functions (Admin:GetSystemStatus)
- [ ] Events received within 3 seconds of emission
- [ ] Connection remains stable (24+ hours)
- [ ] Identity authentication working (ABAC verified)

---

## Phase 3: CQRS Workers Implementation
### Week 2, Days 8-10 (Nov 22-24, 2025)

**Status:** ‚è≥ PENDING

*(To be continued in next iteration)*

---

## Documentation Standards

### Daily Reports
Create daily progress reports in `docs/reports/daily/`:
- `YYYY-MM-DD-progress.md`
- Include: Tasks completed, blockers, next steps
- Metrics: Lines of code, tests written, bugs fixed

### Phase Completion Reports
Create comprehensive reports in `docs/reports/phase-completions/`:
- `phase-N-completion-report.md`
- Include: All deliverables, test results, deployment status
- Lessons learned, performance metrics

### Lecture-Style Documentation
Create educational content in `docs/lectures/`:
- Deep dives into technical decisions
- Step-by-step implementation guides
- Best practices and patterns
- Code examples and explanations

---

## Key Performance Indicators (KPIs)

**Infrastructure:**
- PostgreSQL query latency: p95 <10ms
- Redis response time: p95 <1ms
- Database replication lag: <100ms
- Backup success rate: 100%

**Fabric Integration:**
- Chaincode invocation: p95 <500ms
- Event delivery latency: <3 seconds
- Connection uptime: >99.9%
- Transaction success rate: >99.5%

**API Performance:**
- Request latency: p95 <100ms, p99 <500ms
- Throughput: >1000 requests/second
- Error rate: <0.1%
- Uptime: >99.9%

---

**Next Steps:**
1. Complete Phase 0 documentation setup
2. Begin Phase 1 infrastructure deployment
3. Create first daily progress report
4. Start lecture series on CQRS pattern

